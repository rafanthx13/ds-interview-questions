---
layout: default
title: Redes Neurais PT-BR
description: Questões de Redes Neurais (Conceitos básicos)
---

Step Functions
+ Sigmoid Function
  - y entre [0,1]. O intervalo é de 1
+ Hyper Bolian Tangent Function
  - y é entre [-1,1]. O intervalo é de 2
+ SoftMax function
  - Boa para distribuiçâo de probabildiade (para classificação entre mais de duas classificações)
+ Rectified Linear Unit (ReLu)
  - Uma reta positiva que vai de [0, inf]. Se valor positivo, retorna esse avlor, se neagito, retorna 0.


+ Epochs
 - Unidade de treinamento da rede. Calcular a previsâo, verificar o erros e alterar os pesos pelo BackPropagation
+ HyperParametros: Parametro como (learning-rate (lr))
